{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "DQN_project_MVA.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd5vpJ5jeVHL",
        "colab_type": "text"
      },
      "source": [
        "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "xLFFnWrReVHP",
        "colab_type": "code",
        "outputId": "964d0130-117b-4fb1-d812-2dc29b7b1f6d",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "import skvideo\n",
        "import skvideo.io\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "from keras.models import Sequential,model_from_json\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import sgd\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D, Reshape, BatchNormalization, Flatten, Input"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KH0YscXeVHY",
        "colab_type": "text"
      },
      "source": [
        "# MiniProject #3: Deep Reinforcement Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfM1bJRCeVHZ",
        "colab_type": "text"
      },
      "source": [
        "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c-q8Iy8eVHa",
        "colab_type": "text"
      },
      "source": [
        "# Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5-7gjCQeVHb",
        "colab_type": "text"
      },
      "source": [
        "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
        "\n",
        "\\begin{equation*}\n",
        "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
        "\\end{equation*}\n",
        "\n",
        "where: \n",
        "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "We note the $Q$-function:\n",
        "\n",
        "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}\\left[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a\\right] \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "Thus, the optimal Q function is:\n",
        "\\begin{equation*}\n",
        "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzvS91seeVHd",
        "colab_type": "text"
      },
      "source": [
        "## The environment, the agent and the game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XKzkYYWeVHe",
        "colab_type": "text"
      },
      "source": [
        "### The environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOWeug1ieVHf",
        "colab_type": "text"
      },
      "source": [
        "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am4Sa2PieVHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def act(self, act):\n",
        "        \"\"\"\n",
        "        One can act on the environment and obtain its reaction:\n",
        "        - the new state\n",
        "        - the reward of the new state\n",
        "        - should we continue the game?\n",
        "\n",
        "        :return: state, reward, game_over\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reinitialize the environment to a random state and returns\n",
        "        the original state\n",
        "\n",
        "        :return: state\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def draw(self):\n",
        "        \"\"\"\n",
        "        Visualize in the console or graphically the current state\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8OnMGkoeVHn",
        "colab_type": "text"
      },
      "source": [
        "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
        "\n",
        "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
        "\n",
        "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
        "\n",
        "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsFNu2-4eVHq",
        "colab_type": "text"
      },
      "source": [
        "### The Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJkd0lIgeVHs",
        "colab_type": "text"
      },
      "source": [
        "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl9JLPHveVHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent(object):\n",
        "    def __init__(self, epsilon=0.1, n_action=4):\n",
        "        self.epsilon = epsilon\n",
        "        self.n_action = n_action\n",
        "    \n",
        "    def set_epsilon(self,e):\n",
        "        self.epsilon = e\n",
        "\n",
        "    def act(self,s,train=True):\n",
        "        \"\"\" This function should return the next action to do:\n",
        "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
        "        if train:\n",
        "            if np.random.rand() <= self.epsilon:\n",
        "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
        "            else:\n",
        "                a = self.learned_act(s)\n",
        "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
        "            a = self.learned_act(s)\n",
        "\n",
        "        return a\n",
        "\n",
        "    def learned_act(self,s):\n",
        "        \"\"\" Act via the policy of the agent, from a given state s\n",
        "        it proposes an action a\"\"\"\n",
        "        pass\n",
        "\n",
        "    def reinforce(self, s, n_s, a, r, game_over_):\n",
        "        \"\"\" This function is the core of the learning algorithm. \n",
        "        It takes as an input the current state s_, the next state n_s_\n",
        "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
        "        \n",
        "        Its goal is to learn a policy.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\" This function returns basic stats if applicable: the\n",
        "        loss and/or the model\"\"\"\n",
        "        pass\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\" This function allows to restore a model\"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBYB5C3YeVHz",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 1__:\n",
        "Explain the function act. Why is ```epsilon``` essential?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdLTyYQMeVH1",
        "colab_type": "text"
      },
      "source": [
        "The function `act` selects the optimal learned action with probability `1-epsilon`, and chooses a random action otherwise. The `epsilon` variable represents **how greedy** the agent's behaviour is during the exploration. If `epsilon` is very small, the agent will only take the best actions he has discovered so far, and it may not discover better options. Conversely, if `epsilon` is too big, the agent's behaviour will produce worse rewards. Thus `epsilon` controls the **tradeoff between exploration and exploitation**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpNodlrjeVH3",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "### The Game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2BQuD9IeVH4",
        "colab_type": "text"
      },
      "source": [
        "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
        "\n",
        "```python\n",
        "\n",
        "epoch = 300\n",
        "env = Environment()\n",
        "agent = Agent()\n",
        "\n",
        "\n",
        "# Number of won games\n",
        "score = 0\n",
        "loss = 0\n",
        "\n",
        "\n",
        "for e in range(epoch):\n",
        "    # At each epoch, we restart to a fresh game and get the initial state\n",
        "    state = env.reset()\n",
        "    # This assumes that the games will end\n",
        "    game_over = False\n",
        "\n",
        "    win = 0\n",
        "    lose = 0\n",
        "    \n",
        "    while not game_over:\n",
        "        # The agent performs an action\n",
        "        action = agent.act(state)\n",
        "\n",
        "        # Apply an action to the environment, get the next state, the reward\n",
        "        # and if the games end\n",
        "        prev_state = state\n",
        "        state, reward, game_over = env.act(action)\n",
        "\n",
        "        # Update the counters\n",
        "        if reward > 0:\n",
        "            win = win + reward\n",
        "        if reward < 0:\n",
        "            lose = lose - reward\n",
        "\n",
        "        # Apply the reinforcement strategy\n",
        "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "    # Save as a mp4\n",
        "    if e % 10 == 0:\n",
        "        env.draw(e)\n",
        "\n",
        "    # Update stats\n",
        "    score += win-lose\n",
        "\n",
        "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "          .format(e, epoch, loss, win, lose, win-lose))\n",
        "    agent.save()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZhmX_useVH6",
        "colab_type": "text"
      },
      "source": [
        "# The game, *eat cheese*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI05HTiQeVH8",
        "colab_type": "text"
      },
      "source": [
        "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
        "\n",
        "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_jQjBjWeVH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self, e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self, t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        reward = self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        state = np.concatenate((\n",
        "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwQ1iM1qeVIC",
        "colab_type": "text"
      },
      "source": [
        "The following elements are important because they correspond to the hyper parameters for this project:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud1p2RV9eVIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters\n",
        "size = 13\n",
        "T=200\n",
        "temperature=0.3\n",
        "epochs_train=50 # set small when debugging\n",
        "epochs_test=10 # set small when debugging\n",
        "\n",
        "# display videos\n",
        "def display_videos(name):\n",
        "    video = io.open(name, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    return '''<video alt=\"test\" controls>\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWWe8FrjeVII",
        "colab_type": "text"
      },
      "source": [
        "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLqy3jnqeVII",
        "colab_type": "text"
      },
      "source": [
        "The array `self.position` corresponds to the position of the mouse on the island. It is two cells larger than the island in each direction so as to handle the $5\\times 5$ vision range. The cells outside the island are set to `-1` and the other cells to `0`. The cell where the mouse is located is set to `1`.\n",
        "\n",
        "The array `self.board` contains the rewards available on each cell of the extended island : `0.5` on cheese cells, `-1` on poisonous cells and `0` on empty cells."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G81TI9gKeVIK",
        "colab_type": "text"
      },
      "source": [
        "## Random Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr1HzgEDeVIL",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6L80w-feVIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomAgent(Agent):\n",
        "    def __init__(self):\n",
        "        super(RandomAgent, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        return np.random.randint(self.n_action)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9teXEYqeVIQ",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-1gPOVYeVIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(agent,env,epochs,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "        \n",
        "    for e in range(1, epochs+1):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will end\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose - reward\n",
        "\n",
        "        # Save as a mp4\n",
        "        env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score = score + win-lose\n",
        "\n",
        "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
        "              .format(win, lose, score/(1+e)))\n",
        "    print('Final score: '+str(score/epochs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGUt8rn7eVIV",
        "colab_type": "code",
        "outputId": "80a82584-615a-4da5-9279-67a3fcf6d4f9",
        "colab": {}
      },
      "source": [
        "# Initialize the game\n",
        "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
        "\n",
        "# Initialize the agent!\n",
        "agent = RandomAgent()\n",
        "\n",
        "test(agent,env,epochs_test,prefix='random')\n",
        "HTML(display_videos('random0.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 9.0/16.0. Average score (-3.5)\n",
            "Win/lose count 9.5/18.0. Average score (-5.166666666666667)\n",
            "Win/lose count 13.5/16.0. Average score (-4.5)\n",
            "Win/lose count 15.5/20.0. Average score (-4.5)\n",
            "Win/lose count 13.0/7.0. Average score (-2.75)\n",
            "Win/lose count 9.0/14.0. Average score (-3.0714285714285716)\n",
            "Win/lose count 13.0/9.0. Average score (-2.1875)\n",
            "Win/lose count 10.5/15.0. Average score (-2.4444444444444446)\n",
            "Win/lose count 16.0/12.0. Average score (-1.8)\n",
            "Win/lose count 9.5/17.0. Average score (-2.3181818181818183)\n",
            "Final score: -2.55\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RsEGVtQeVIZ",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "## DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRaKPeJIeVIa",
        "colab_type": "text"
      },
      "source": [
        "Let us assume here that $T=\\infty$.\n",
        "\n",
        "***\n",
        "__Question 5__ Let $\\pi$ be a policy, show that:\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a)=E_{(s',a')\\sim p^\\pi(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{equation*}\n",
        "\n",
        "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{*}(s,a)=E_{s'\\sim p(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
        "\\end{equation*}\n",
        "Finally, deduce that a plausible objective is:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim p(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdDYBY8qeVIb",
        "colab_type": "text"
      },
      "source": [
        "- We prove that $Q^\\pi$ satisfies the *Bellman equation* :\n",
        "\n",
        "\\begin{align}\n",
        "Q^\\pi(s,a) &= E_{p^{\\pi}}\\left[\\sum_{t \\ge 0}\\gamma^{t}r(s_{t},a_{t}) ~\\middle|~ s_{0}=s,a_{0}=a\\right] \\\\\n",
        "&= E_{p^{\\pi}}\\left[r(s_0,a_0) + \\gamma \\sum_{t \\ge 1}\\gamma^{t-1}r(s_{t},a_{t}) ~\\middle|~ s_{0}=s,a_{0}=a\\right] \\\\\n",
        "&= E_{(s',a')\\sim p^\\pi(.|s,a)}\\left[r(s, a) + \\gamma E_{p^{\\pi}} \\left[ \\sum_{t \\ge 0}\\gamma^{t}r(s_{t-1},a_{t-1}) ~\\middle|~ s_1=s', a_1=a' \\right] ~\\middle|~ s_{0}=s,a_{0}=a\\right] \\\\\n",
        "&= E_{(s',a')\\sim p^\\pi(.|s,a)}\\left[r(s, a) + \\gamma Q^\\pi (s', a')\\right]\n",
        "\\end{align}\n",
        "\n",
        "- We now prove the *optimal Bellman equation*. In discrete Markov Decision Processes, there is always a deterministic optimal policy among optimal policies (because it is optimal to choose the action with the highest cumulated expected reward). Let $\\pi^*$ be deterministic such as $Q^*=Q^{\\pi^*}$. For each state $s$, there exists an action $a$ such that $\\pi^*(a|s) = 1$, and $Q^{\\pi^*}(s,a)=\\max_{a'} Q^{\\pi^*}(s, a')$ (otherwise $\\pi^*$ is not optimal). Let us denote $\\pi^*(s)$ this action (classical notation when handling deterministic policies). This means that we have :\n",
        "\n",
        "\\begin{align}\n",
        "Q^*(s,a) &= Q^{\\pi^*}(s,a) = E_{s' \\sim p(.|s,a)}\\left[r(s, a) + \\gamma Q^{\\pi^*} (s', \\pi^*(s'))\\right] \\\\\n",
        "&= E_{s' \\sim p(.|s,a)}\\left[r(s, a) + \\gamma \\max_{a'} Q^{\\pi^*} (s', a')\\right] \\\\\n",
        "&= E_{s' \\sim p(.|s,a)}\\left[r(s, a) + \\gamma \\max_{a'} Q^* (s', a')\\right]\n",
        "\\end{align}\n",
        "\n",
        "- The last inequality can be rewritten $E_{s' \\sim p(.|s,a)}\\left[r(s, a) + \\gamma \\max_{a'} Q^* (s', a') - Q^*(s,a)\\right] = 0$, a natural idea is to minimize the norm of this quantity. Thus a logical loss would look like $\\mathcal{L}(\\theta)=E_{s' \\sim p(.|s,a)}\\Vert r+\\gamma\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytfREHmieVId",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
        "\n",
        "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
        "\n",
        "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
        "\n",
        "3. Store $(s_t,a_t,s_{t+1})$;\n",
        "\n",
        "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
        "\n",
        "***\n",
        "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mJMnTHseVIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Memory(object):\n",
        "    def __init__(self, max_memory=100):\n",
        "        self.max_memory = max_memory\n",
        "        self.memory = list()\n",
        "\n",
        "    def remember(self, m):\n",
        "        self.memory.append(m)\n",
        "        if len(self.memory) > self.max_memory:\n",
        "            self.memory.pop(0)\n",
        "\n",
        "    def random_access(self):\n",
        "        return self.memory[np.random.randint(len(self.memory))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcbBVhx9eVIh",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The pipeline we will use for training is given below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evjnhBhTeVIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(agent, env, epoch, prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(1, epoch+1):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5', name_model=prefix+'model.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp3FVZBHeVIm",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrc3jnLReVIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN(Agent):\n",
        "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16, n_state=2):\n",
        "        super(DQN, self).__init__(epsilon = epsilon)\n",
        "\n",
        "        # Discount for Q learning\n",
        "        self.discount = 0.99\n",
        "        \n",
        "        self.grid_size = grid_size\n",
        "        \n",
        "        # number of state\n",
        "        self.n_state = n_state\n",
        "\n",
        "        # Memory\n",
        "        self.memory = Memory(memory_size)\n",
        "        \n",
        "        # Batch size when learning\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        s_batch = s[None]\n",
        "        value_predictions = self.model.predict(s_batch)\n",
        "        return value_predictions.argmax()\n",
        "\n",
        "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
        "        # Two steps: first memorize the states, second learn from the pool\n",
        "\n",
        "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
        "        \n",
        "        input_states = np.zeros((self.batch_size, 5, 5, self.n_state))\n",
        "        target_q = np.zeros((self.batch_size, 4))\n",
        "        \n",
        "        for i in range(self.batch_size):\n",
        "            # We retrieve a random element from the memory\n",
        "            s_, n_s_, a_, r_, game_over_ = self.memory.random_access()\n",
        "            \n",
        "            # We now fill target_q using the value prediction at state n_s_\n",
        "            input_states[i, :, :, :] = s_\n",
        "            target_q[i, a_] = r_\n",
        "            # We compute the target with the optimality criterion (=> use a max)\n",
        "            if not game_over_:\n",
        "                prediction_input = n_s_.reshape((1, 5, 5, self.n_state))\n",
        "                prediction = self. model.predict(prediction_input)\n",
        "                target_q[i] += r_ + self.discount * max(prediction)\n",
        "        \n",
        "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
        "        target_q = np.clip(target_q, -3, 3)\n",
        "\n",
        "        l = self.model.train_on_batch(input_states, target_q)\n",
        "\n",
        "        return l\n",
        "\n",
        "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
        "        self.model.save_weights(name_weights, overwrite=True)\n",
        "        with open(name_model, \"w\") as outfile:\n",
        "            json.dump(self.model.to_json(), outfile)\n",
        "            \n",
        "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
        "        with open(name_model, \"r\") as jfile:\n",
        "            model = model_from_json(json.load(jfile))\n",
        "        model.load_weights(name_weights)\n",
        "        model.compile(\"sgd\", \"mse\")\n",
        "        self.model = model\n",
        "\n",
        "            \n",
        "class DQN_FC(DQN):\n",
        "    def __init__(self, *args, lr=0.1,**kwargs):\n",
        "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
        "        \n",
        "        # NN Model\n",
        "        model = Sequential()\n",
        "        model.add(Flatten(input_shape=(5, 5, self.n_state)))\n",
        "        model.add(Dense(32, activation=\"relu\"))\n",
        "        model.add(Dense(16, activation=\"relu\"))\n",
        "        model.add(Dense(4, activation=None)) # No activation on the last layer since it is a regression problem\n",
        "        \n",
        "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        self.model = model\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghcGOLateVIs",
        "colab_type": "code",
        "outputId": "c7973a0b-fed4-4a2e-99d7-3cb46eb9494d",
        "colab": {}
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_FC(size, lr=.1, epsilon = 0.2, memory_size=1000, batch_size = 64)\n",
        "train(agent, env, epochs_train, prefix='fc_train')\n",
        "HTML(display_videos('fc_train{}.mp4'.format(epochs_train)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 001/050 | Loss 0.0392 | Win/lose count 7.0/10.0 (-3.0)\n",
            "Epoch 002/050 | Loss 0.0410 | Win/lose count 2.5/7.0 (-4.5)\n",
            "Epoch 003/050 | Loss 0.0693 | Win/lose count 7.0/4.0 (3.0)\n",
            "Epoch 004/050 | Loss 0.0750 | Win/lose count 7.5/13.0 (-5.5)\n",
            "Epoch 005/050 | Loss 0.0712 | Win/lose count 3.5/3.0 (0.5)\n",
            "Epoch 006/050 | Loss 0.0471 | Win/lose count 3.5/3.0 (0.5)\n",
            "Epoch 007/050 | Loss 0.0655 | Win/lose count 6.5/1.0 (5.5)\n",
            "Epoch 008/050 | Loss 0.0755 | Win/lose count 4.0/7.0 (-3.0)\n",
            "Epoch 009/050 | Loss 0.0976 | Win/lose count 4.5/7.0 (-2.5)\n",
            "Epoch 010/050 | Loss 0.0542 | Win/lose count 3.5/2.0 (1.5)\n",
            "Epoch 011/050 | Loss 0.0412 | Win/lose count 4.5/8.0 (-3.5)\n",
            "Epoch 012/050 | Loss 0.0268 | Win/lose count 1.5/7.0 (-5.5)\n",
            "Epoch 013/050 | Loss 0.0300 | Win/lose count 0.5/7.0 (-6.5)\n",
            "Epoch 014/050 | Loss 0.0349 | Win/lose count 3.0/3.0 (0.0)\n",
            "Epoch 015/050 | Loss 0.0512 | Win/lose count 1.0/6.0 (-5.0)\n",
            "Epoch 016/050 | Loss 0.0327 | Win/lose count 2.5/5.0 (-2.5)\n",
            "Epoch 017/050 | Loss 0.0669 | Win/lose count 6.5/7.0 (-0.5)\n",
            "Epoch 018/050 | Loss 0.0562 | Win/lose count 3.5/8.0 (-4.5)\n",
            "Epoch 019/050 | Loss 0.0628 | Win/lose count 4.5/6.0 (-1.5)\n",
            "Epoch 020/050 | Loss 0.0183 | Win/lose count 4.5/9.0 (-4.5)\n",
            "Epoch 021/050 | Loss 0.0519 | Win/lose count 2.0/10.0 (-8.0)\n",
            "Epoch 022/050 | Loss 0.1784 | Win/lose count 6.0/8.0 (-2.0)\n",
            "Epoch 023/050 | Loss 0.0669 | Win/lose count 3.5/3.0 (0.5)\n",
            "Epoch 024/050 | Loss 0.0396 | Win/lose count 6.0/3.0 (3.0)\n",
            "Epoch 025/050 | Loss 0.0667 | Win/lose count 5.5/15.0 (-9.5)\n",
            "Epoch 026/050 | Loss 0.1452 | Win/lose count 2.5/2.0 (0.5)\n",
            "Epoch 027/050 | Loss 0.0352 | Win/lose count 5.0/6.0 (-1.0)\n",
            "Epoch 028/050 | Loss 0.0916 | Win/lose count 5.0/8.0 (-3.0)\n",
            "Epoch 029/050 | Loss 0.0298 | Win/lose count 2.5/3.0 (-0.5)\n",
            "Epoch 030/050 | Loss 0.0771 | Win/lose count 2.0/5.0 (-3.0)\n",
            "Epoch 031/050 | Loss 0.0363 | Win/lose count 1.5/7.0 (-5.5)\n",
            "Epoch 032/050 | Loss 0.0395 | Win/lose count 4.0/1.0 (3.0)\n",
            "Epoch 033/050 | Loss 0.0533 | Win/lose count 2.0/3.0 (-1.0)\n",
            "Epoch 034/050 | Loss 0.0209 | Win/lose count 5.5/12.0 (-6.5)\n",
            "Epoch 035/050 | Loss 0.0231 | Win/lose count 3.0/6.0 (-3.0)\n",
            "Epoch 036/050 | Loss 0.0347 | Win/lose count 2.0/5.0 (-3.0)\n",
            "Epoch 037/050 | Loss 0.0202 | Win/lose count 4.0/0 (4.0)\n",
            "Epoch 038/050 | Loss 0.0373 | Win/lose count 1.5/4.0 (-2.5)\n",
            "Epoch 039/050 | Loss 0.0308 | Win/lose count 4.5/4.0 (0.5)\n",
            "Epoch 040/050 | Loss 0.0377 | Win/lose count 5.5/6.0 (-0.5)\n",
            "Epoch 041/050 | Loss 0.0673 | Win/lose count 5.0/6.0 (-1.0)\n",
            "Epoch 042/050 | Loss 0.0508 | Win/lose count 3.0/5.0 (-2.0)\n",
            "Epoch 043/050 | Loss 0.0582 | Win/lose count 1.0/6.0 (-5.0)\n",
            "Epoch 044/050 | Loss 0.0791 | Win/lose count 2.5/4.0 (-1.5)\n",
            "Epoch 045/050 | Loss 0.1762 | Win/lose count 4.0/4.0 (0.0)\n",
            "Epoch 046/050 | Loss 0.0204 | Win/lose count 5.0/6.0 (-1.0)\n",
            "Epoch 047/050 | Loss 0.0232 | Win/lose count 5.5/2.0 (3.5)\n",
            "Epoch 048/050 | Loss 0.0347 | Win/lose count 3.5/2.0 (1.5)\n",
            "Epoch 049/050 | Loss 0.0606 | Win/lose count 2.0/9.0 (-7.0)\n",
            "Epoch 050/050 | Loss 0.0261 | Win/lose count 1.5/1.0 (0.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRSMCAMoeVIw",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtBXwoZSeVIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN_CNN(DQN):\n",
        "    def __init__(self, *args,lr=0.1,**kwargs):\n",
        "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
        "        \n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(filters=32, kernel_size=2, activation=\"relu\", padding=\"valid\", input_shape=(5, 5, self.n_state)))\n",
        "        model.add(Conv2D(filters=16, kernel_size=2, activation=\"relu\"))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4, activation=None))\n",
        "        \n",
        "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        self.model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "jgBlCoizeVI1",
        "colab_type": "code",
        "outputId": "5bd4ae4b-cf07-498e-c761-8d4af67e1620",
        "colab": {}
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "train(agent,env,epochs_train,prefix='cnn_train')\n",
        "HTML(display_videos('cnn_train{}.mp4'.format(epochs_train)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 001/050 | Loss 0.0142 | Win/lose count 2.5/4.0 (-1.5)\n",
            "Epoch 002/050 | Loss 0.0704 | Win/lose count 2.0/4.0 (-2.0)\n",
            "Epoch 003/050 | Loss 0.0190 | Win/lose count 5.0/5.0 (0.0)\n",
            "Epoch 004/050 | Loss 0.0487 | Win/lose count 4.0/6.0 (-2.0)\n",
            "Epoch 005/050 | Loss 0.0102 | Win/lose count 1.5/3.0 (-1.5)\n",
            "Epoch 006/050 | Loss 0.1027 | Win/lose count 3.5/4.0 (-0.5)\n",
            "Epoch 007/050 | Loss 0.0754 | Win/lose count 1.5/8.0 (-6.5)\n",
            "Epoch 008/050 | Loss 0.0220 | Win/lose count 8.0/4.0 (4.0)\n",
            "Epoch 009/050 | Loss 0.0942 | Win/lose count 5.5/5.0 (0.5)\n",
            "Epoch 010/050 | Loss 0.0773 | Win/lose count 5.5/4.0 (1.5)\n",
            "Epoch 011/050 | Loss 0.0901 | Win/lose count 1.5/5.0 (-3.5)\n",
            "Epoch 012/050 | Loss 0.1609 | Win/lose count 3.5/2.0 (1.5)\n",
            "Epoch 013/050 | Loss 0.0533 | Win/lose count 4.5/1.0 (3.5)\n",
            "Epoch 014/050 | Loss 0.1289 | Win/lose count 3.5/1.0 (2.5)\n",
            "Epoch 015/050 | Loss 0.0295 | Win/lose count 3.0/4.0 (-1.0)\n",
            "Epoch 016/050 | Loss 0.0609 | Win/lose count 4.5/0 (4.5)\n",
            "Epoch 017/050 | Loss 0.1286 | Win/lose count 6.0/6.0 (0.0)\n",
            "Epoch 018/050 | Loss 0.0509 | Win/lose count 1.0/3.0 (-2.0)\n",
            "Epoch 019/050 | Loss 0.0251 | Win/lose count 5.5/4.0 (1.5)\n",
            "Epoch 020/050 | Loss 0.1015 | Win/lose count 3.5/5.0 (-1.5)\n",
            "Epoch 021/050 | Loss 0.0091 | Win/lose count 3.0/2.0 (1.0)\n",
            "Epoch 022/050 | Loss 0.0492 | Win/lose count 9.5/1.0 (8.5)\n",
            "Epoch 023/050 | Loss 0.0127 | Win/lose count 5.0/4.0 (1.0)\n",
            "Epoch 024/050 | Loss 0.0179 | Win/lose count 3.5/0 (3.5)\n",
            "Epoch 025/050 | Loss 0.0511 | Win/lose count 6.0/3.0 (3.0)\n",
            "Epoch 026/050 | Loss 0.0271 | Win/lose count 8.0/5.0 (3.0)\n",
            "Epoch 027/050 | Loss 0.0212 | Win/lose count 4.0/3.0 (1.0)\n",
            "Epoch 028/050 | Loss 0.1010 | Win/lose count 6.5/5.0 (1.5)\n",
            "Epoch 029/050 | Loss 0.0231 | Win/lose count 5.5/6.0 (-0.5)\n",
            "Epoch 030/050 | Loss 0.0465 | Win/lose count 3.0/2.0 (1.0)\n",
            "Epoch 031/050 | Loss 0.0284 | Win/lose count 6.5/2.0 (4.5)\n",
            "Epoch 032/050 | Loss 0.0554 | Win/lose count 3.0/5.0 (-2.0)\n",
            "Epoch 033/050 | Loss 0.0315 | Win/lose count 5.0/3.0 (2.0)\n",
            "Epoch 034/050 | Loss 0.0374 | Win/lose count 2.0/2.0 (0.0)\n",
            "Epoch 035/050 | Loss 0.0594 | Win/lose count 2.0/5.0 (-3.0)\n",
            "Epoch 036/050 | Loss 0.0122 | Win/lose count 2.5/3.0 (-0.5)\n",
            "Epoch 037/050 | Loss 0.0293 | Win/lose count 3.0/2.0 (1.0)\n",
            "Epoch 038/050 | Loss 0.0679 | Win/lose count 5.5/2.0 (3.5)\n",
            "Epoch 039/050 | Loss 0.0616 | Win/lose count 3.0/7.0 (-4.0)\n",
            "Epoch 040/050 | Loss 0.0454 | Win/lose count 4.5/2.0 (2.5)\n",
            "Epoch 041/050 | Loss 0.0229 | Win/lose count 2.5/4.0 (-1.5)\n",
            "Epoch 042/050 | Loss 0.0296 | Win/lose count 5.5/0 (5.5)\n",
            "Epoch 043/050 | Loss 0.0301 | Win/lose count 5.5/0 (5.5)\n",
            "Epoch 044/050 | Loss 0.0649 | Win/lose count 6.0/2.0 (4.0)\n",
            "Epoch 045/050 | Loss 0.0598 | Win/lose count 3.5/0 (3.5)\n",
            "Epoch 046/050 | Loss 0.0091 | Win/lose count 3.5/4.0 (-0.5)\n",
            "Epoch 047/050 | Loss 0.0427 | Win/lose count 6.0/4.0 (2.0)\n",
            "Epoch 048/050 | Loss 0.0115 | Win/lose count 5.5/2.0 (3.5)\n",
            "Epoch 049/050 | Loss 0.0994 | Win/lose count 4.5/1.0 (3.5)\n",
            "Epoch 050/050 | Loss 0.0233 | Win/lose count 4.0/2.0 (2.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_axeTD1FeVI4",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38EqTscQeVI5",
        "colab_type": "code",
        "outputId": "f08ddbd9-92f8-4045-901e-c857918970b8",
        "colab": {}
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T,temperature=0.3)\n",
        "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
        "\n",
        "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
        "print('Test of the CNN')\n",
        "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
        "print('Test of the FC')\n",
        "test(agent_fc,env,epochs_test,prefix='fc_test')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test of the CNN\n",
            "Win/lose count 3.5/3.0. Average score (0.25)\n",
            "Win/lose count 2.0/4.0. Average score (-0.5)\n",
            "Win/lose count 0/2.0. Average score (-0.875)\n",
            "Win/lose count 3.0/2.0. Average score (-0.5)\n",
            "Win/lose count 4.5/3.0. Average score (-0.16666666666666666)\n",
            "Win/lose count 4.0/1.0. Average score (0.2857142857142857)\n",
            "Win/lose count 3.0/2.0. Average score (0.375)\n",
            "Win/lose count 4.5/2.0. Average score (0.6111111111111112)\n",
            "Win/lose count 2.5/4.0. Average score (0.4)\n",
            "Win/lose count 4.0/5.0. Average score (0.2727272727272727)\n",
            "Final score: 0.3\n",
            "Test of the FC\n",
            "Win/lose count 0/4.0. Average score (-2.0)\n",
            "Win/lose count 0.5/3.0. Average score (-2.1666666666666665)\n",
            "Win/lose count 3.0/4.0. Average score (-1.875)\n",
            "Win/lose count 3.0/6.0. Average score (-2.1)\n",
            "Win/lose count 4.0/1.0. Average score (-1.25)\n",
            "Win/lose count 7.5/11.0. Average score (-1.5714285714285714)\n",
            "Win/lose count 3.0/5.0. Average score (-1.625)\n",
            "Win/lose count 3.5/4.0. Average score (-1.5)\n",
            "Win/lose count 3.5/2.0. Average score (-1.2)\n",
            "Win/lose count 3.0/4.0. Average score (-1.1818181818181819)\n",
            "Final score: -1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "3h3eVcxLeVI-",
        "colab_type": "code",
        "outputId": "f9873de8-9343-46cc-92a6-162ff6c84594",
        "colab": {}
      },
      "source": [
        "HTML(display_videos('cnn_test10.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "wXzaF6GxeVJC",
        "colab_type": "code",
        "outputId": "bdd51797-5e10-4b0f-c7e6-471ac32a6795",
        "colab": {}
      },
      "source": [
        "HTML(display_videos('fc_test10.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAFettZGF0AAACnwYF//+b3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiAtIEguMjY0L01QRUctNCBBVkMgY29kZWMgLSBDb3B5bGVmdCAyMDAzLTIwMTcgLSBodHRwOi8vd3d3LnZpZGVvbGFuLm9yZy94MjY0Lmh0bWwgLSBvcHRpb25zOiBjYWJhYz0xIHJlZj0zIGRlYmxvY2s9MTowOjAgYW5hbHlzZT0weDE6MHgxMTEgbWU9aGV4IHN1Ym1lPTcgcHN5PTEgcHN5X3JkPTEuMDA6MC4wMCBtaXhlZF9yZWY9MSBtZV9yYW5nZT0xNiBjaHJvbWFfbWU9MSB0cmVsbGlzPTEgOHg4ZGN0PTAgY3FtPTAgZGVhZHpvbmU9MjEsMTEgZmFzdF9wc2tpcD0xIGNocm9tYV9xcF9vZmZzZXQ9NCB0aHJlYWRzPTYgbG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTI1IHNjZW5lY3V0PTQwIGludHJhX3JlZnJlc2g9MCByY19sb29rYWhlYWQ9NDAgcmM9Y3JmIG1idHJlZT0xIGNyZj0yMy4wIHFjb21wPTAuNjAgcXBtaW49MCBxcG1heD02OSBxcHN0ZXA9NCBpcF9yYXRpbz0xLjQwIGFxPTE6MS4wMACAAAAC7WWIhAAz//72hvgU2FMj/k+//CP/uR+3H1n64sZCCb61XkPRgDJfGv+ZRmGl6cnPLe0fr0zQBGc/GUvKWafaPwKZray+ZW/3ATGyrUAJY2pniUWub8AdU1zYzM/4pabB6VGJ4Oh54K3sexGyqPuQUEhlVX0G3RnmoB7balGMFJjpCR0jtmV53/LzSK/gVZ+BSidGb0SvAFPTCtsI2OC2qPI6po/CpGbUA9GxEsLOIu7UGNiFUWlQqx36vvU88IEmqYZ/ANRV5hmEuwaBqY4BSKRpdClR+1IlDolCOjqV8Roe+E4uLZupX4T5qcItFKQK/2w3FqBQZjeeBJrpqGN4HE+PKczdYlTef7Zdk+VxAoRxUYr+d/K5YHqe1YUbm52xJGo0HPsfxKy0xQ6yMN0zPdmIW5Zdv73+X5ANJFXI2+IJ0I4fNVi8puixAMzZsvEs/Sp6V10/WuLpB6yVyWFim00i1Gb9SEd284gSY6hQDhWNvPOw/4EAN4EYcSiNQKeMjRQkhUL8vFHYEU7kmzeGrYeyLIYoTd+FruN3tBxR1fB5506AUlWQyJqBt2NfPoQcHluxRcJ02+wVJMfkW5qt44DNy+jKwGHzYVRYi/il6DDREWQ8mBmaYlAuIkpHVKkXeGg9N+pdh9Dc35zy73gNpqd/cPqzWhHLwAqvH9l5u7BchFLPAXpPMnTvZS9Ltz7W2k5Tn+NTRAu4qxSjmowA14EaBnlPWeJb1JnzCi6Old/PrD3SnWK26O07Avg+DLw0GsFtfC0xK2kZw+JdCDD8WsEifyXgWrlTbON8nt3FyV9EHLt2kSE7vHISQd9oIs4zZZm+0zMAn6gnDH3QxVahyTeFN002IJW8F+QuleqepgLpJ97YHXFMHVdw1TtEKrcPeHQCT8QznTyHoYaJ5l1tnBKHD3LyoBw8vYNmwSHwPye+aCBE8bm+VqV+3Ikc8jPtqIkzgEIoeBQ2ivYmIuMMg+lyI0GwoKXim8qUAAH9AAAAE0GaIWxDP/6eEAB0fX3esm7i4XQAAAAXQZpCPCGTKYQ3//6nhAAdH2D17M+CLKcAAAAaQZpjSeEPJlMCG//+p4QAHG9lYYnXsz4IsrwAAAAYQZqFSeEPJlMFETw3//6nhAAa+kT/VdrxAAAADwGepGpCvwAWvlA8mCN2gQAAABtBmqZJ4Q8mUwId//6plgAN98QgH94WoJ/YHtEAAAAbQZrJSeEPJlMCHf/+qZYAFS+QZoA9JefbeTcNAAAAEUGe50URPCv/ACG7O/6OSKuLAAAADgGfCGpCvwAhuz1zXq4sAAAAJUGbDUmoQWiZTAh3//6plgAgKrIjh7dsAMsubuBfDTUdBDP7rN0AAAAQQZ8rRREsL/8AJrPWqHtKMAAAABABn0p0Qr8ANNZV3IbKlJfgAAAADwGfTGpCvwA0wLGiVzy7gQAAABNBm1FJqEFsmUwId//+qZYAAJWBAAAADEGfb0UVLC//AACygQAAABABn450Qr8ANM8m6O2+Fd6AAAAADwGfkGpCvwA0wLGiVzy7gQAAABNBm5VJqEFsmUwId//+qZYAAJWBAAAADEGfs0UVLC//AACygAAAABABn9J0Qr8ANM8m6O2+Fd6AAAAADwGf1GpCvwA0wLGiVzy7gQAAABJBm9lJqEFsmUwIb//+p4QAAScAAAAMQZ/3RRUsL/8AALKBAAAAEAGeFnRCvwA0zybo7b4V3oEAAAAPAZ4YakK/ADTAsaJXPLuBAAAAGkGaHEmoQWyZTAhv//6nhAA/YPCnWdPut16BAAAAD0GeOkUVLCv/ADTEaBsNwAAAAA0BnltqQr8ANNYkW9hvAAAAGUGaXUmoQWyZTAh3//6plgAylSDM/EB7px0AAAASQZphSeEKUmUwId/+qZYAAJWAAAAADEGen0U0TC//AACygAAAABABnr50Qr8AUO2tunZdlY+BAAAAEAGeoGpCvwBQ7a2wz1Z69IAAAAATQZqlSahBaJlMCHf//qmWAACVgQAAAAxBnsNFESwv/wAAsoAAAAAQAZ7idEK/AFDtrbp2XZWPgQAAABABnuRqQr8AUO2tsM9WevSBAAAAE0Ga6UmoQWyZTAh3//6plgAAlYEAAAAMQZ8HRRUsL/8AALKBAAAAEAGfJnRCvwBQ7a26dl2Vj4AAAAAQAZ8oakK/AFDtrbDPVnr0gAAAABNBmy1JqEFsmUwId//+qZYAAJWBAAAADEGfS0UVLC//AACygAAAABABn2p0Qr8AUO2tunZdlY+AAAAADwGfbGpCvwBUOFBr7u2u6QAAABNBm3FJqEFsmUwId//+qZYAAJWBAAAADEGfj0UVLC//AACygQAAAA8Bn650Qr8AVCHoZ7YBYuAAAAAQAZ+wakK/AFDtrbDPVnr0gAAAABNBm7VJqEFsmUwId//+qZYAAJWBAAAADEGf00UVLC//AACygAAAABABn/J0Qr8AUO2tunZdlY+AAAAAEAGf9GpCvwBQ7a2wz1Z69IEAAAATQZv5SahBbJlMCHf//qmWAACVgAAAAAxBnhdFFSwv/wAAsoEAAAAQAZ42dEK/AFDtrbp2XZWPgQAAABABnjhqQr8AUO2tsM9WevSAAAAAE0GaPUmoQWyZTAh3//6plgAAlYEAAAAMQZ5bRRUsL/8AALKAAAAAEAGeenRCvwBQ7a26dl2Vj4EAAAAQAZ58akK/AFDtrbDPVnr0gQAAABJBmmFJqEFsmUwIb//+p4QAAScAAAAMQZ6fRRUsL/8AALKAAAAAEAGevnRCvwBQ7a26dl2Vj4EAAAAQAZ6gakK/AFDtrbDPVnr0gAAAABxBmqRJqEFsmUwIb//+p4QAZP4DAJr17M+CK9bBAAAAD0GewkUVLCv/AFHa3DXlQAAAAA0BnuNqQr8AUflIt68rAAAAHEGa5UmoQWyZTAh3//6plgBMEWG6MQl0Dh/iFlEAAAAWQZsJSeEKUmUwId/+qZYAThFhujEmpQAAAA5BnydFNEwv/wBdGVAwIQAAABABn0Z0Qr8AfFsDW+ljaK1oAAAAEAGfSGpCvwB8OcNfVB08t/gAAAATQZtNSahBaJlMCHf//qmWAACVgQAAAAxBn2tFESwv/wAAsoAAAAAQAZ+KdEK/AHxbA1vpY2itaAAAABABn4xqQr8AfDnDX1QdPLf5AAAAE0GbkUmoQWyZTAh3//6plgAAlYEAAAAMQZ+vRRUsL/8AALKBAAAAEAGfznRCvwB8WwNb6WNorWgAAAAQAZ/QakK/AHw5w19UHTy3+AAAABNBm9VJqEFsmUwId//+qZYAAJWBAAAADEGf80UVLC//AACygAAAABABnhJ0Qr8AfFsDW+ljaK1oAAAAEAGeFGpCvwB8OcNfVB08t/kAAAATQZoZSahBbJlMCHf//qmWAACVgAAAAAxBnjdFFSwv/wAAsoEAAAAQAZ5WdEK/AHxbA1vpY2itaQAAABABnlhqQr8AfDnDX1QdPLf4AAAAE0GaXUmoQWyZTAh3//6plgAAlYEAAAAMQZ57RRUsL/8AALKAAAAAEAGemnRCvwB8WwNb6WNorWkAAAAQAZ6cakK/AHw5w19UHTy3+QAAABNBmoFJqEFsmUwId//+qZYAAJWAAAAADEGev0UVLC//AACygAAAABABnt50Qr8AfFsDW+ljaK1pAAAAEAGewGpCvwB8OcNfVB08t/gAAAATQZrFSahBbJlMCHf//qmWAACVgQAAAAxBnuNFFSwv/wAAsoAAAAAQAZ8CdEK/AHxbA1vpY2itaQAAABABnwRqQr8AfDnDX1QdPLf5AAAAEkGbCUmoQWyZTAhv//6nhAABJwAAAAxBnydFFSwv/wAAsoEAAAAQAZ9GdEK/AHxbA1vpY2itaAAAABABn0hqQr8AfDnDX1QdPLf4AAAAEkGbTUmoQWyZTAhv//6nhAABJwAAAAxBn2tFFSwv/wAAsoAAAAAQAZ+KdEK/AHxbA1vpY2itaAAAABABn4xqQr8AfDnDX1QdPLf5AAAAGkGbjkmoQWyZTAh3//6plgBOCjnSaIbweQv9AAAAFkGbsknhClJlMCG//qeEAJ98dPtcrYEAAAAOQZ/QRTRML/8AX4RbN6AAAAAQAZ/vdEK/AH8bA1vpY2itGAAAAA8Bn/FqQr8AexYBdZ6s9UEAAAAcQZv0SahBaJlMFPDf/qeEAJt9HPx/Ms1TW5juBAAAAA8BnhNqQr8AfEH9UigSqakAAAAZQZoVSeEKUmUwId/+qZYAMZ7S/ndIUwidMQAAABJBmjlJ4Q6JlMCHf/6plgAAlYAAAAAMQZ5XRRE8L/8AALKBAAAAEAGednRCvwA0zybo7b4V3oEAAAAPAZ54akK/ADTAsaJXPLuBAAAAHEGafUmoQWiZTAh3//6plgAykFmLTNAd30Y9cLMAAAAQQZ6bRREsL/8AO2nTv83mqAAAAA8Bnrp0Qr8ANM8m884twIEAAAAQAZ68akK/AFHsI8mB69v5gQAAABNBmqFJqEFsmUwId//+qZYAAJWAAAAADEGe30UVLC//AACygAAAAA8Bnv50Qr8AUOyjiOy7Kx8AAAAPAZ7gakK/AFDso3WerPXpAAAAE0Ga5UmoQWyZTAh3//6plgAAlYEAAAAMQZ8DRRUsL/8AALKAAAAADwGfInRCvwBUIehntgFi4QAAAA8BnyRqQr8AUOyjdZ6s9ekAAAATQZspSahBbJlMCHf//qmWAACVgQAAAAxBn0dFFSwv/wAAsoEAAAAPAZ9mdEK/AFDso4jsuysfAAAADwGfaGpCvwBQ7KN1nqz16QAAABNBm21JqEFsmUwId//+qZYAAJWBAAAADEGfi0UVLC//AACygAAAAA8Bn6p0Qr8AUOyjiOy7Kx8AAAAPAZ+sakK/AFDso3WerPXpAAAAE0GbsUmoQWyZTAh3//6plgAAlYEAAAAMQZ/PRRUsL/8AALKBAAAADwGf7nRCvwBQ7KOI7LsrHwAAAA8Bn/BqQr8AUOyjdZ6s9ekAAAATQZv1SahBbJlMCHf//qmWAACVgQAAAAxBnhNFFSwv/wAAsoAAAAAPAZ4ydEK/AFQh6Ge2AWLgAAAADwGeNGpCvwBQ7KN1nqz16QAAABxBmjlJqEFsmUwId//+qZYATAo6hBmgU+jH6Yv8AAAAEEGeV0UVLC//AFroEVpRQ6UAAAAPAZ52dEK/AFHjCAyS5Y+BAAAAEAGeeGpCvwB5mfMbockHF/gAAAATQZp9SahBbJlMCHf//qmWAACVgQAAAAxBnptFFSwv/wAAsoAAAAAQAZ66dEK/AHxbA1vpY2itaQAAABABnrxqQr8AfDnDX1QdPLf5AAAAE0GaoUmoQWyZTAh3//6plgAAlYAAAAAMQZ7fRRUsL/8AALKAAAAAEAGe/nRCvwB8WwNb6WNorWkAAAAQAZ7gakK/AHw5w19UHTy3+AAAABNBmuVJqEFsmUwId//+qZYAAJWBAAAADEGfA0UVLC//AACygAAAABABnyJ0Qr8AfFsDW+ljaK1pAAAAEAGfJGpCvwB8OcNfVB08t/kAAAATQZspSahBbJlMCHf//qmWAACVgQAAAAxBn0dFFSwv/wAAsoEAAAAQAZ9mdEK/AHxbA1vpY2itaAAAABABn2hqQr8AfDnDX1QdPLf4AAAAE0GbbUmoQWyZTAh3//6plgAAlYEAAAAMQZ+LRRUsL/8AALKAAAAAEAGfqnRCvwB8WwNb6WNorWgAAAAQAZ+sakK/AHw5w19UHTy3+QAAABNBm7FJqEFsmUwId//+qZYAAJWBAAAADEGfz0UVLC//AACygQAAABABn+50Qr8AfFsDW+ljaK1oAAAAEAGf8GpCvwB8OcNfVB08t/gAAAATQZv1SahBbJlMCHf//qmWAACVgQAAAAxBnhNFFSwv/wAAsoAAAAAQAZ4ydEK/AHxbA1vpY2itaAAAABABnjRqQr8AfDnDX1QdPLf5AAAAE0GaOUmoQWyZTAh3//6plgAAlYAAAAAMQZ5XRRUsL/8AALKBAAAAEAGednRCvwB8WwNb6WNorWkAAAAQAZ54akK/AHw5w19UHTy3+AAAABNBmn1JqEFsmUwId//+qZYAAJWBAAAADEGem0UVLC//AACygAAAABABnrp0Qr8AfFsDW+ljaK1pAAAAEAGevGpCvwB8OcNfVB08t/kAAAASQZqhSahBbJlMCG///qeEAAEnAAAADEGe30UVLC//AACygAAAABABnv50Qr8AfFsDW+ljaK1pAAAAEAGe4GpCvwB8OcNfVB08t/gAAAASQZrlSahBbJlMCGf//p4QAAR9AAAADEGfA0UVLC//AACygAAAABABnyJ0Qr8AfFsDW+ljaK1pAAAAEAGfJGpCvwB8OcNfVB08t/kAAAAaQZspS6hCEFskRggoB/IB/YeAIV/+OEAAEXEAAAArQZ9HRRUsL/8CAdzqS9szCrmA6Bq1qFxMwBzXGcIKeXqI2HEDqGYKkaEgnwAAABABn2Z0Qr8Aw8iyrwIrttSAAAAAJQGfaGpCvwKvY+1BxN2qw0km5aqGC5gaYT68GuUfFmMZ/CS4PfgAAAxYbW9vdgAAAGxtdmhkAAAAAAAAAAAAAAAAAAAD6AAAH5AAAQAAAQAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAAC4J0cmFrAAAAXHRraGQAAAADAAAAAAAAAAAAAAABAAAAAAAAH5AAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAARAAAAEQAAAAAAAkZWR0cwAAABxlbHN0AAAAAAAAAAEAAB+QAAAEAAABAAAAAAr6bWRpYQAAACBtZGhkAAAAAAAAAAAAAAAAAAAyAAABlABVxAAAAAAALWhkbHIAAAAAAAAAAHZpZGUAAAAAAAAAAAAAAABWaWRlb0hhbmRsZXIAAAAKpW1pbmYAAAAUdm1oZAAAAAEAAAAAAAAAAAAAACRkaW5mAAAAHGRyZWYAAAAAAAAAAQAAAAx1cmwgAAAAAQAACmVzdGJsAAAAlXN0c2QAAAAAAAAAAQAAAIVhdmMxAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAARABEABIAAAASAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGP//AAAAL2F2Y0MB9AAN/+EAF2f0AA2RmygiEdCAAAADAIAAABkHihTLAQAFaOvjxEgAAAAYc3R0cwAAAAAAAAABAAAAygAAAgAAAAAUc3RzcwAAAAAAAAABAAAAAQAABjBjdHRzAAAAAAAAAMQAAAAEAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAABxzdHNjAAAAAAAAAAEAAAABAAAAygAAAAEAAAM8c3RzegAAAAAAAAAAAAAAygAABZQAAAAXAAAAGwAAAB4AAAAcAAAAEwAAAB8AAAAfAAAAFQAAABIAAAApAAAAFAAAABQAAAATAAAAFwAAABAAAAAUAAAAEwAAABcAAAAQAAAAFAAAABMAAAAWAAAAEAAAABQAAAATAAAAHgAAABMAAAARAAAAHQAAABYAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABMAAAAXAAAAEAAAABMAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFgAAABAAAAAUAAAAFAAAACAAAAATAAAAEQAAACAAAAAaAAAAEgAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABYAAAAQAAAAFAAAABQAAAAWAAAAEAAAABQAAAAUAAAAHgAAABoAAAASAAAAFAAAABMAAAAgAAAAEwAAAB0AAAAWAAAAEAAAABQAAAATAAAAIAAAABQAAAATAAAAFAAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAACAAAAAUAAAAEwAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAWAAAAEAAAABQAAAAUAAAAFgAAABAAAAAUAAAAFAAAAB4AAAAvAAAAFAAAACkAAAAUc3RjbwAAAAAAAAABAAAAMAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTguMTIuMTAw\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjQZkIa0eVJG",
        "colab_type": "text"
      },
      "source": [
        "The CNN performs overall better than the FC network, and it is better at avoiding the poisonnous states. However, **both agents have a hard time exploring the state space**: most of the time they get stucked in a left-right or up-down loop.\n",
        "\n",
        "Coherently, the temperature has a big impact on the agents' average score. When it is too small (e.g. 0.1), the agents struggle finding interesting states, and both the CNN and FCN get negative final scores. On the contrary, when the temperature gets high (e.g. 0.7), many state provide a positive reward, so that both agents get positive final scores. Besides, the CNN remains better than the FCN no matter what temperature we choose. Overall, 0.3 seems to be an equilibrate compromise between the two extremes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ncDt0LueVJH",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "\n",
        "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
        "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
        "2. Append via the environment a new state that describes if a cell has been visited or not\n",
        "\n",
        "***\n",
        "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlOIAnX0eVJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_explore(agent,env,epoch,epsilon_decay=1,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(1, epoch+1):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action, train=True)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "        \n",
        "        # Decrease the exploration rate\n",
        "        agent.set_epsilon(agent.epsilon * epsilon_decay)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, round(win, 2), round(lose, 2), round(win-lose, 2)))\n",
        "        agent.save(name_weights=prefix+'model.h5', name_model=prefix+'model.json')\n",
        "\n",
        "class EnvironmentExploring(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "        self.malus_position = np.zeros((grid_size,grid_size))\n",
        "\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self, e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self, t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action, train=False):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        \n",
        "        reward = 0\n",
        "        # Exploration malus\n",
        "        if train:\n",
        "            reward = -self.malus_position[self.x, self.y] # Punish the agent if the state was visited before\n",
        "        self.malus_position[self.x, self.y] = 0.1 # Mark the current state as visited\n",
        "        # Normal bonus\n",
        "        reward = reward + self.board[self.x, self.y]\n",
        "        \n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "        \n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        # The state now includes wether the surrounding states were visited before\n",
        "        # 3 \"feature\" states instead of 2\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "    \n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state\n",
        "\n",
        "## use those samples of code:\n",
        "#In train explore:\n",
        "# state, reward, game_over = env.act(action, train=True)\n",
        "\n",
        "## In Environment exploring:\n",
        "# You will have to change n_state to 3 because you will use one more layer!\n",
        "# reward = 0\n",
        "# if train:\n",
        "#     reward = -self.malus_position[self.x, self.y]\n",
        "# self.malus_position[self.x, self.y] = 0.1\n",
        "# reward = reward + self.board[self.x, self.y]\n",
        "\n",
        "# 3 \"feature\" states instead of 2\n",
        "# state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "#                                 self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "#                         self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlBlJLWveVJL",
        "colab_type": "code",
        "outputId": "2f881d8b-2a04-4998-cf31-0aabd14c9c45",
        "colab": {}
      },
      "source": [
        "# Training\n",
        "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=0.1, epsilon=0.7, memory_size=1000, batch_size=64, n_state=3)\n",
        "train_explore(agent, env, epochs_train, epsilon_decay=0.95, prefix='cnn_train_explore')\n",
        "HTML(display_videos('cnn_train_explore{}.mp4'.format(epochs_train)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 001/050 | Loss 0.0273 | Win/lose count 6.5/29.0 (-22.5)\n",
            "Epoch 002/050 | Loss 0.0289 | Win/lose count 7.8/25.5 (-17.7)\n",
            "Epoch 003/050 | Loss 0.1670 | Win/lose count 2.0/27.1 (-25.1)\n",
            "Epoch 004/050 | Loss 0.1687 | Win/lose count 7.7/34.0 (-26.3)\n",
            "Epoch 005/050 | Loss 0.0185 | Win/lose count 10.8/34.9 (-24.1)\n",
            "Epoch 006/050 | Loss 0.0408 | Win/lose count 8.5/21.8 (-13.3)\n",
            "Epoch 007/050 | Loss 0.0473 | Win/lose count 10.2/31.6 (-21.4)\n",
            "Epoch 008/050 | Loss 0.0560 | Win/lose count 10.4/29.4 (-19.0)\n",
            "Epoch 009/050 | Loss 0.0409 | Win/lose count 6.4/24.5 (-18.1)\n",
            "Epoch 010/050 | Loss 0.0588 | Win/lose count 12.2/33.9 (-21.7)\n",
            "Epoch 011/050 | Loss 0.0487 | Win/lose count 11.6/33.2 (-21.6)\n",
            "Epoch 012/050 | Loss 0.2862 | Win/lose count 8.0/27.1 (-19.1)\n",
            "Epoch 013/050 | Loss 0.1080 | Win/lose count 17.6/31.6 (-14.0)\n",
            "Epoch 014/050 | Loss 0.0884 | Win/lose count 15.2/29.3 (-14.1)\n",
            "Epoch 015/050 | Loss 0.0932 | Win/lose count 10.8/25.4 (-14.6)\n",
            "Epoch 016/050 | Loss 0.1869 | Win/lose count 10.8/33.4 (-22.6)\n",
            "Epoch 017/050 | Loss 0.0931 | Win/lose count 7.6/31.2 (-23.6)\n",
            "Epoch 018/050 | Loss 0.0467 | Win/lose count 16.0/31.1 (-15.1)\n",
            "Epoch 019/050 | Loss 0.0472 | Win/lose count 12.4/34.0 (-21.6)\n",
            "Epoch 020/050 | Loss 0.0744 | Win/lose count 15.2/32.3 (-17.1)\n",
            "Epoch 021/050 | Loss 0.3104 | Win/lose count 14.4/23.5 (-9.1)\n",
            "Epoch 022/050 | Loss 0.0876 | Win/lose count 8.8/26.9 (-18.1)\n",
            "Epoch 023/050 | Loss 0.1289 | Win/lose count 17.2/21.8 (-4.6)\n",
            "Epoch 024/050 | Loss 0.1115 | Win/lose count 7.2/33.3 (-26.1)\n",
            "Epoch 025/050 | Loss 0.3328 | Win/lose count 16.8/23.9 (-7.1)\n",
            "Epoch 026/050 | Loss 0.1215 | Win/lose count 15.2/24.3 (-9.1)\n",
            "Epoch 027/050 | Loss 0.0849 | Win/lose count 18.8/34.4 (-15.6)\n",
            "Epoch 028/050 | Loss 0.0681 | Win/lose count 17.2/23.8 (-6.6)\n",
            "Epoch 029/050 | Loss 0.2179 | Win/lose count 4.0/25.1 (-21.1)\n",
            "Epoch 030/050 | Loss 0.2150 | Win/lose count 10.8/25.4 (-14.6)\n",
            "Epoch 031/050 | Loss 0.0857 | Win/lose count 16.8/19.9 (-3.1)\n",
            "Epoch 032/050 | Loss 0.0800 | Win/lose count 12.4/24.0 (-11.6)\n",
            "Epoch 033/050 | Loss 0.2086 | Win/lose count 13.2/26.8 (-13.6)\n",
            "Epoch 034/050 | Loss 0.0932 | Win/lose count 18.8/34.4 (-15.6)\n",
            "Epoch 035/050 | Loss 0.1761 | Win/lose count 19.6/29.2 (-9.6)\n",
            "Epoch 036/050 | Loss 0.1382 | Win/lose count 12.4/25.0 (-12.6)\n",
            "Epoch 037/050 | Loss 0.0926 | Win/lose count 14.4/31.5 (-17.1)\n",
            "Epoch 038/050 | Loss 0.0775 | Win/lose count 16.8/31.9 (-15.1)\n",
            "Epoch 039/050 | Loss 0.2127 | Win/lose count 18.4/32.5 (-14.1)\n",
            "Epoch 040/050 | Loss 0.2510 | Win/lose count 16.0/26.1 (-10.1)\n",
            "Epoch 041/050 | Loss 0.1824 | Win/lose count 10.8/25.4 (-14.6)\n",
            "Epoch 042/050 | Loss 0.1316 | Win/lose count 7.6/32.2 (-24.6)\n",
            "Epoch 043/050 | Loss 0.1852 | Win/lose count 20.0/29.1 (-9.1)\n",
            "Epoch 044/050 | Loss 0.1016 | Win/lose count 19.2/30.3 (-11.1)\n",
            "Epoch 045/050 | Loss 0.0859 | Win/lose count 10.4/29.5 (-19.1)\n",
            "Epoch 046/050 | Loss 0.1666 | Win/lose count 7.6/29.2 (-21.6)\n",
            "Epoch 047/050 | Loss 0.0516 | Win/lose count 17.6/23.7 (-6.1)\n",
            "Epoch 048/050 | Loss 0.0666 | Win/lose count 13.6/29.7 (-16.1)\n",
            "Epoch 049/050 | Loss 0.0448 | Win/lose count 15.6/26.2 (-10.6)\n",
            "Epoch 050/050 | Loss 0.1692 | Win/lose count 14.8/31.4 (-16.6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVvCVGnGeVJQ",
        "colab_type": "code",
        "outputId": "f3d7b8fe-6f3d-4736-edc4-dca414b4740c",
        "colab": {}
      },
      "source": [
        "# Evaluation\n",
        "test(agent,env,epochs_test,prefix='cnn_test_explore')\n",
        "HTML(display_videos('cnn_test_explore10.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 23.0/7.0. Average score (8.0)\n",
            "Win/lose count 18.5/5.0. Average score (9.833333333333334)\n",
            "Win/lose count 22.0/8.0. Average score (10.875)\n",
            "Win/lose count 21.5/8.0. Average score (11.4)\n",
            "Win/lose count 15.0/6.0. Average score (11.0)\n",
            "Win/lose count 7.0/2.0. Average score (10.142857142857142)\n",
            "Win/lose count 10.5/1.0. Average score (10.0625)\n",
            "Win/lose count 18.0/4.0. Average score (10.5)\n",
            "Win/lose count 11.5/3.0. Average score (10.3)\n",
            "Win/lose count 23.0/10.0. Average score (10.545454545454545)\n",
            "Final score: 11.6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAGLFtZGF0AAACnwYF//+b3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiAtIEguMjY0L01QRUctNCBBVkMgY29kZWMgLSBDb3B5bGVmdCAyMDAzLTIwMTcgLSBodHRwOi8vd3d3LnZpZGVvbGFuLm9yZy94MjY0Lmh0bWwgLSBvcHRpb25zOiBjYWJhYz0xIHJlZj0zIGRlYmxvY2s9MTowOjAgYW5hbHlzZT0weDE6MHgxMTEgbWU9aGV4IHN1Ym1lPTcgcHN5PTEgcHN5X3JkPTEuMDA6MC4wMCBtaXhlZF9yZWY9MSBtZV9yYW5nZT0xNiBjaHJvbWFfbWU9MSB0cmVsbGlzPTEgOHg4ZGN0PTAgY3FtPTAgZGVhZHpvbmU9MjEsMTEgZmFzdF9wc2tpcD0xIGNocm9tYV9xcF9vZmZzZXQ9NCB0aHJlYWRzPTYgbG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTI1IHNjZW5lY3V0PTQwIGludHJhX3JlZnJlc2g9MCByY19sb29rYWhlYWQ9NDAgcmM9Y3JmIG1idHJlZT0xIGNyZj0yMy4wIHFjb21wPTAuNjAgcXBtaW49MCBxcG1heD02OSBxcHN0ZXA9NCBpcF9yYXRpbz0xLjQwIGFxPTE6MS4wMACAAAAC+2WIhAA3//72h/gU2VgT/lm//Q1/3I/bj6z9cWMhBN9aryHowBkvtR/m/6xRbOmelAf34AiUAHNuGcKR2SeOovVZBjg+BTV0nV8CkoUD6LaHS/EMSV8vKE+APUKO2jAuCNwwpoWQ5lNo0pfKLRbM1zlITUfw2I7WVZLyKWyFpHBuH/vmTcSCbETevKcE+c2qImxJB6XbdmdELGDDifj7JOCPafBAhSZrYh0vT4MGFPX2aPNZkoFFcq9KJSRp7t3yqzC8/VKQ05DAgDMyfK6jy/nXsAmbncW6rkibFPfGxYxi+43jI5gwd4l+YOkC4AWDe5W69xTy9tLxcqNhRtyt8qA+EzHqegEoL2eK8snhZuFbeEP+5yV8ECzgDPetqGi+Y2h9gHBkiFh8FA4nMt3nAm/3lb5lbrfrv4A3NYWbmmy8yuL/H8MAmoYiUCOVSMjrA3ddGCh3S1nQ8H9f2C3hSjABvCGthlkvn5+xI5X5smdJWGG05AAAuErVFZz9oRk3EpspdcwAMJ8H7d+ZZ62Dtr24rojAk+tJYO8dvqZK583lyEzoeYIiNbZFh2X6Y87Gqz+Yhr5glX9drIAD90E8UPEJXW2T53eDfEMqnmuDzp4clE7dDXRHhpGj2xKpJ/K5ow1mQQPhKV/qj+ulsJdx5xTHz3zPm1uY/2NAgej9bV7H7W7FIuI5/sPQ9d99zrTqgnstLa8dUgYIy+WUfiNzqU6AsHvL3IeTHCH+F6yJmYmsNAakaGLZ4cz7kTZuMcDqO5ymIKiqa8WIo+E/wYCyYLreXFyCGK8JNsGHzaeffOFzWYieb+Jpayj4oYn1KB01IJVa6S/yTjunZXiMvuVnphmCCrPbMrJ9eCGU+ISi5hK4C3bXGYuuL1eBi8+5fMIt8ad3x0A2qiLVw3f0VQQJAZziZVsyLD/jCyGA5UAS3n4xr52yHIDeVv4KNI94io3qOo3I3tJx4mX/aYPrCbi5jzO98mUBl4IKff37loB/0HdGgFyGIn1auOAAGHEAAAAZQZoibEM//p4QBdPaj8PboULgU2lu1mcb0AAAABABnkF5Cv8BNrWu3tZCR9lBAAAAGEGaQzwhkymEN//+p4QA8vsH+E4LdCRdwAAAABlBmmRJ4Q8mUwIb//6nhACffHT6jjQkOFTBAAAAG0Gah0nhDyZTAhn//p4QAZtfcaF033Wfo2ZQgQAAABJBnqVFETwr/wBWbCvYWC/LpoEAAAAOAZ7GakK/AFZsTHnBBTUAAAAaQZrISahBaJlMCG///qeEAKL6J/qt8x+IUkAAAAAfQZrqSeEKUmUwURLDf/6nhAD8g8OLGp7EDRxif4GcaAAAABABnwlqQr8A0rtS3DZtTLyBAAAAHUGbDUnhDomUwIZ//p4QBofGCDH/ofvcaFoeRdg4AAAAEkGfK0UVPCv/AUjB13mMHarVBAAAABABn0xqQr8BUY2u3tYZI+khAAAAGUGbTkmoQWiZTAhn//6eEAQQQ4/ngv5IZcUAAAAbQZtvSeEKUmUwIZ/+nhAHBU45+zN1AUz9JMCBAAAAGUGbkEnhDomUwIZ//p4QBwVOOXfi75z6fMAAAAAZQZuxSeEPJlMCG//+p4QFj0T/T2sx9hzpgAAAAB5Bm9NJ4Q8mUwURPDf//qeEBY9FMtHmN17ISNJCRsEAAAAPAZ/yakK/AgrWUzbMgmKmAAAAHEGb9UnhDyZTBTwz//6eEBEu1H2tMsTdTrau07oAAAAQAZ4UakK/Aeu3Bh9ASDSPmQAAABhBmhZJ4Q8mUwIZ//6eEAaHum+ehx9Xyi4AAAAZQZo3SeEPJlMCG//+p4QA/fsH+E4LdCRZQQAAAB5BmllJ4Q8mUwURPDP//p4QAqHum9wA5Tzl8RV0TKkAAAAQAZ54akK/AIrmjeaYq2kQwAAAABlBmnpJ4Q8mUwIb//6nhABu/YP8JwW6EmfBAAAAGEGam0nhDyZTAhv//qeEAEe+OmP8Pq23XwAAAB5Bmr1J4Q8mUwURPDf//qeEAEW+Onu83X31sxQj9SkAAAAQAZ7cakK/ADigvOdaGF5dwQAAABtBmsBJ4Q8mUwIb//6nhAAsfupx/h9WD5vDIsAAAAASQZ7+RRE8K/8AI7KAIBTAOVBAAAAAEAGfH2pCvwAiu0Qm4z69P7kAAAAZQZsBSahBaJlMCG///qeEACte6nH+H1bcIwAAABxBmyVJ4QpSZTAhn/6eEAD5e/u7TpGwXoOu90qZAAAAE0GfQ0U0TC//ACfJv9NFY6fBl3AAAAAQAZ9idEK/ADYSLKvAiu5AgQAAAA8Bn2RqQr8ANgRfM2zI158AAAAZQZtmSahBaJlMCGf//p4QAPP6+/kSI+sJvQAAABhBm4dJ4QpSZTAhn/6eEACjV7jQum+6320AAAAdQZupSeEOiZTBTRMM//6eEACke6b7AWuyYtgqmOAAAAAPAZ/IakK/ACGyuRV4AoATAAAAGEGbyknhDyZTAhn//p4QAEO+If2yGPrDlQAAABpBm+tJ4Q8mUwIZ//6eEAAsfvASv8iRH1iNwAAAABlBmgxJ4Q8mUwIb//6nhAAHR9g/wnBboYHAAAAAGEGaLUnhDyZTAhv//qeEAATUfMeRif5cowAAAB9Bmk9J4Q8mUwURPDf//qeEAAeUHhxY1PS17jtHPwZjAAAAEAGebmpCvwAGSdqW4bNrJoEAAAAmQZpySeEPJlMCG//+p4QADJ/Alc5llc94/ApUtn4FM7AxcXNF0Y8AAAASQZ6QRRE8K/8ACj2Q3+w3nZc2AAAAEAGesWpCvwAKPY8tw2bVsIEAAAAcQZq1SahBaJlMCG///qeEAAzvsH82l3NMFueQsAAAABFBntNFESwr/wAKhSjeab3rVwAAAA4BnvRqQr8ACoNjHoixUwAAAB5BmvhJqEFsmUwIZ//+nhAAHy9ff0K6OlvTl8w1aj0AAAATQZ8WRRUsK/8ABpiW/gP09ZwZwQAAABABnzdqQr8ABDZZDD6AkH+JAAAAGUGbOUmoQWyZTAhn//6eEAANyvuNC6b7sYYAAAAZQZtaSeEKUmUwIb/+p4QAA54PCnWdPuxcgQAAACBBm3xJ4Q6JlMFNEwz//p4QABaq9zXHL7bUluMx88/uhQAAAA8Bn5tqQr8ABLdiPJgevr8AAAAXQZudSeEPJlMCGf/+nhAAIqcI5+l/dHMAAAAYQZu+SeEPJlMCGf/+nhAAIt85s63QMkh8AAAAGUGb30nhDyZTAhv//qeEAA19In+q3zH4vSAAAAAyQZvhSeEPJlMFETw3//6nhAAf3cZr8QjvL//CVCCWL//CMxWL//CT4D/LDOIxtDXk+4EAAAAQAZ4AakK/ABpnajlf24gRwAAAABhBmgRJ4Q8mUwIZ//6eEADDyGOfowHZoS8AAAARQZ4iRRE8K/8AKPY7/o5Iq0kAAAAQAZ5DakK/ACj2EeTA9e55gQAAABlBmkVJqEFomUwIZ//+nhABLThHP4c5vrP/AAAAGEGaZknhClJlMCGf/p4QATUQ4/ngv5Ic7QAAAB9BmohJ4Q6JlMFNEwz//p4QAeT1yN2OEnsdizm+9lLhAAAAEAGep2pCvwBnHaluGzamwYAAAAAYQZqpSeEPJlMCGf/+nhAC98GOfowHZn4+AAAAGEGayknhDyZTAhn//p4QBJDhHP4c5vrKDwAAABlBmutJ4Q8mUwIb//6nhAEsQBZgx2ZNW1gQAAAAGEGbDEnhDyZTAhv//qeEASX46Y/w+rbZVQAAADBBmy5J4Q8mUwURPDf//qeEB+whcfEIAf/wlRBZi//wkxH4v/9f/FBVQIT+eLDqVv0AAAAQAZ9NakK/AkjO8Cv7RPlvQQAAABhBm1JJ4Q8mUwIb//6nhAcfZz8WWy3qLuEAAAATQZ9wRRE8L/8BsuIZkqz92r+mqgAAABABn490Qr8CR8MBklcIznzAAAAADwGfkWpCvwJIzvRw2bSpGwAAABhBm5NJqEFomUwIb//+p4QHso5WIoTwAk4AAAAbQZu3SeEKUmUwIZ/+nhAHx6C/fVE5fEVZYJOAAAAAEEGf1UU0TC//AQagOXkT6mEAAAAQAZ/0dEK/AWxOpPK/JTZR8AAAAA8Bn/ZqQr8BdY2u77vduqEAAAAcQZv5SahBaJlMFPDP/p4QBHfiH+MV3I3ZsKo6YQAAABABnhhqQr8A7QRM030kHFBwAAAAGEGaGknhClJlMCGf/p4QAvvum+ipWa9+PwAAABhBmjtJ4Q6JlMCGf/6eEAHv9cbe9N91t3oAAAAYQZpcSeEPJlMCGf/+nhAB8vX38iRH1hGzAAAAGEGafUnhDyZTAhn//p4QAUj3TfRUrNfApwAAABlBmp5J4Q8mUwIb//6nhAA2PsH+E4LdCWpAAAAAGEGav0nhDyZTAhv//qeEACLfHTH+H1bcZwAAABhBmsNJ4Q8mUwIZ//6eEABWvid+CutyQEEAAAASQZ7hRRE8L/8AFHyVuNUH9CTcAAAAEAGfAHRCvwAboBC4D8oABuEAAAAQAZ8CakK/ABunajlf24gNwAAAABlBmwRJqEFomUwIb//+p4QAId8dMf4fVtxxAAAAGUGbJUnhClJlMCG//qeEADN0if6rfMfiP8EAAAAXQZtISeEOiZTAhv/+p4QAM77B/hWOY/0AAAASQZ9mRRE8K/8AP4/A6Em61hdBAAAADgGfh2pCvwA/gQLO/CyaAAAAHUGbjEmoQWiZTAhv//6nhAAg3x0+1Xls+FGt0S09AAAAEEGfqkURLC//ABPmUlLbPiEAAAAQAZ/JdEK/ABsAD4pNslX0gAAAAA8Bn8tqQr8AGmStjCs29EAAAAAdQZvOSahBbJlMFEw3//6nhAAfAHia41RL9E/yJ4kAAAAQAZ/takK/ABnHbhNxn16hzQAAABlBm+9J4QpSZTAhv/6nhAAw9In+q3zH4kPBAAAAHUGaEUnhDomUwU0TDf/+p4QAMT77Pe+Alsgy2r1YAAAAEAGeMGpCvwAnzXznVMxvM0AAAAAcQZozSeEPJlMFPDf//qeEAC6+6n7mRhbMUI5iBQAAABABnlJqQr8AJbJ851oYXoTAAAAAGEGaVknhDyZTAhn//p4QALDwY5/DnN9avQAAABJBnnRFETwr/wAkuzwISMfuUYEAAAAOAZ6VakK/ACS7PXT9TowAAAAZQZqXSahBaJlMCGf//p4QAQ04Rz+HOb60PwAAABhBmrhJ4QpSZTAhn/6eEAGlkMc/hzm+s3cAAAAYQZrZSeEOiZTAhn/+nhACi8GOfw5zfWXdAAAAGUGa+knhDyZTAhv//qeEAPycZ/qt8x+IM+EAAAAZQZsbSeEPJlMCG//+p4QBrmif6nv7Pk1xwAAAAB1Bmz1J4Q8mUwURPDv//qmWAtKWYtMz5avRj0kKCQAAAA8Bn1xqQr8CC2EeTAqeu0EAAAAcQZtfSeEPJlMFPDv//qmWA36RtmjR/nmnYizGLAAAAA8Bn35qQr8CMuqeS5nu6P8AAAASQZtjSeEPJlMCHf/+qZYAAJWBAAAAE0GfgUURPC//AaPoG5SOmcsVotIAAAAQAZ+gdEK/AkjYGtpg4K+HgQAAABABn6JqQr8CR84a95XCfGLAAAAAG0Gbp0moQWiZTAh3//6plgObpdA4f5WgOC4OmQAAABBBn8VFESwv/wGjQEV3Gi0hAAAAEAGf5HRCvwJI2BraYOCvh4EAAAAPAZ/makK/AkhqHQmm0HNBAAAAE0Gb60moQWyZTAh3//6plgAAlYAAAAAMQZ4JRRUsL/8AALKAAAAAEAGeKHRCvwJJYrF6NA43nYEAAAAQAZ4qakK/AkhqHP6vDjedgAAAABNBmi9JqEFsmUwId//+qZYAAJWAAAAADEGeTUUVLC//AACygQAAABABnmx0Qr8CSWKxejQON52BAAAAEAGebmpCvwJIahz+rw43nYEAAAATQZpzSahBbJlMCHf//qmWAACVgAAAAAxBnpFFFSwv/wAAsoAAAAAQAZ6wdEK/AklisXo0DjedgQAAABABnrJqQr8CSGoc/q8ON52AAAAAE0Gat0moQWyZTAh3//6plgAAlYAAAAAMQZ7VRRUsL/8AALKBAAAAEAGe9HRCvwJJYrF6NA43nYAAAAAQAZ72akK/AkhqHP6vDjedgQAAABNBmvtJqEFsmUwId//+qZYAAJWBAAAADEGfGUUVLC//AACygAAAABABnzh0Qr8CSWKxejQON52BAAAAEAGfOmpCvwJIahz+rw43nYAAAAATQZs/SahBbJlMCHf//qmWAACVgQAAAAxBn11FFSwv/wAAsoEAAAAQAZ98dEK/AklisXo0DjedgAAAABABn35qQr8CSGoc/q8ON52AAAAAE0GbY0moQWyZTAh3//6plgAAlYEAAAAMQZ+BRRUsL/8AALKAAAAAEAGfoHRCvwJJYrF6NA43nYEAAAAQAZ+iakK/AkhqHP6vDjedgAAAABNBm6dJqEFsmUwId//+qZYAAJWBAAAADEGfxUUVLC//AACygQAAABABn+R0Qr8CSWKxejQON52BAAAAEAGf5mpCvwJIahz+rw43nYEAAAATQZvrSahBbJlMCHf//qmWAACVgAAAAAxBnglFFSwv/wAAsoAAAAAQAZ4odEK/AklisXo0DjedgQAAABABnipqQr8CSGoc/q8ON52AAAAAE0GaL0moQWyZTAh3//6plgAAlYAAAAAMQZ5NRRUsL/8AALKBAAAAEAGebHRCvwJJYrF6NA43nYEAAAAQAZ5uakK/AkhqHP6vDjedgQAAABNBmnNJqEFsmUwId//+qZYAAJWAAAAADEGekUUVLC//AACygAAAABABnrB0Qr8CSWKxejQON52BAAAAEAGesmpCvwJIahz+rw43nYAAAAATQZq3SahBbJlMCHf//qmWAACVgAAAAAxBntVFFSwv/wAAsoEAAAAQAZ70dEK/AklisXo0DjedgAAAABABnvZqQr8CSGoc/q8ON52BAAAAE0Ga+0moQWyZTAh3//6plgAAlYEAAAAMQZ8ZRRUsL/8AALKAAAAAEAGfOHRCvwJJYrF6NA43nYEAAAAQAZ86akK/AkhqHP6vDjedgAAAABJBmz9JqEFsmUwIb//+p4QAAScAAAAMQZ9dRRUsL/8AALKBAAAAEAGffHRCvwJJYrF6NA43nYAAAAAQAZ9+akK/AkhqHP6vDjedgAAAABJBm2NJqEFsmUwIb//+p4QAAScAAAAMQZ+BRRUsL/8AALKAAAAAEAGfoHRCvwJJYrF6NA43nYEAAAAQAZ+iakK/AkhqHP6vDjedgAAAABJBm6dJqEFsmUwIZ//+nhAABH0AAAAMQZ/FRRUsL/8AALKBAAAAEAGf5HRCvwJJYrF6NA43nYEAAAAQAZ/makK/AkhqHP6vDjedgQAAABtBm+lLqEIQWyRGCCgH8gH9h4BRMK/+OEAAEXAAAAAlAZ4IakK/Aq9j7UHKPd7S6FlNNrD0MmkK7NV1Vy8xp7+LoXB+/AAAC2htb292AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAAAfkAABAAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAAKknRyYWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAAAAAfkAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAABEAAAARAAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAAAQAAH5AAAAQAAAEAAAAACgptZGlhAAAAIG1kaGQAAAAAAAAAAAAAAAAAADIAAAGUAFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAAAFZpZGVvSGFuZGxlcgAAAAm1bWluZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJlZgAAAAAAAAABAAAADHVybCAAAAABAAAJdXN0YmwAAACVc3RzZAAAAAAAAAABAAAAhWF2YzEAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAABEAEQAEgAAABIAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY//8AAAAvYXZjQwH0AA3/4QAXZ/QADZGbKCIR0IAAAAMAgAAAGQeKFMsBAAVo6+PESAAAABhzdHRzAAAAAAAAAAEAAADKAAACAAAAABRzdHNzAAAAAAAAAAEAAAABAAAFQGN0dHMAAAAAAAAApgAAAAEAAAQAAAAAAQAABgAAAAABAAACAAAAAAIAAAQAAAAAAQAACAAAAAACAAACAAAAAAEAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAAEAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAgAABAAAAAABAAAGAAAAAAEAAAIAAAAAAgAABAAAAAABAAAGAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAACAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAAEAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAgAAAAAAgAAAgAAAAACAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAADAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAgAABAAAAAABAAAGAAAAAAEAAAIAAAAABAAABAAAAAABAAAGAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAYAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAACAAAEAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAUAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAADKAAAAAQAAAzxzdHN6AAAAAAAAAAAAAADKAAAFogAAAB0AAAAUAAAAHAAAAB0AAAAfAAAAFgAAABIAAAAeAAAAIwAAABQAAAAhAAAAFgAAABQAAAAdAAAAHwAAAB0AAAAdAAAAIgAAABMAAAAgAAAAFAAAABwAAAAdAAAAIgAAABQAAAAdAAAAHAAAACIAAAAUAAAAHwAAABYAAAAUAAAAHQAAACAAAAAXAAAAFAAAABMAAAAdAAAAHAAAACEAAAATAAAAHAAAAB4AAAAdAAAAHAAAACMAAAAUAAAAKgAAABYAAAAUAAAAIAAAABUAAAASAAAAIgAAABcAAAAUAAAAHQAAAB0AAAAkAAAAEwAAABsAAAAcAAAAHQAAADYAAAAUAAAAHAAAABUAAAAUAAAAHQAAABwAAAAjAAAAFAAAABwAAAAcAAAAHQAAABwAAAA0AAAAFAAAABwAAAAXAAAAFAAAABMAAAAcAAAAHwAAABQAAAAUAAAAEwAAACAAAAAUAAAAHAAAABwAAAAcAAAAHAAAAB0AAAAcAAAAHAAAABYAAAAUAAAAFAAAAB0AAAAdAAAAGwAAABYAAAASAAAAIQAAABQAAAAUAAAAEwAAACEAAAAUAAAAHQAAACEAAAAUAAAAIAAAABQAAAAcAAAAFgAAABIAAAAdAAAAHAAAABwAAAAdAAAAHQAAACEAAAATAAAAIAAAABMAAAAWAAAAFwAAABQAAAAUAAAAHwAAABQAAAAUAAAAEwAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAWAAAAEAAAABQAAAAUAAAAFgAAABAAAAAUAAAAFAAAABYAAAAQAAAAFAAAABQAAAAfAAAAKQAAABRzdGNvAAAAAAAAAAEAAAAwAAAAYnVkdGEAAABabWV0YQAAAAAAAAAhaGRscgAAAAAAAAAAbWRpcmFwcGwAAAAAAAAAAAAAAAAtaWxzdAAAACWpdG9vAAAAHWRhdGEAAAABAAAAAExhdmY1OC4xMi4xMDA=\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmU6N1HSeVJY",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMeGfDbweVJa",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpjXdsBoeVJb",
        "colab_type": "text"
      },
      "source": [
        "***"
      ]
    }
  ]
}